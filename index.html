<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Qian Zheng, ZJU, Zhejiang University"> 
<meta name="description" content="Qian Zheng's homepage">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Qian Zheng's homepage, Zhejiang University</title>

<div id="layout-content" style="margin-top:25px">

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1><font face="Georgia"> Qian Zheng </font>   <font face="STKaiTi" size=6 color="0000">  郑   乾</font></h1>
				</div>

				<h3><font face="Georgia" color=000 size=4> <b>Assistant Professor</b> </font></h3>
				<p><font face="Georgia"> 
					College of Computer Science and Technology, <br>
					Zhejiang University, Hangzhou, China. <br>
				
					Email: <a href="qianzheng@zju.edu.cn">qianzheng@zju.edu.cn</a> <br>
					Official Academic Profile: [<a href="https://person.zju.edu.cn/en/zq">En</a>][<a href="https://person.zju.edu.cn/zq"><font face="STKaiTi">中文</font></a>]<br>
				</font></p>

				<p> <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=ztWK59MAAAAJ"><img src="./figs/google_scholariconv1.png" height="80px" style="margin-bottom:-3px"></a>

			  <a href="#News"><img src="./figs/news_iconv1.png" height="80px" style="margin-bottom:-3px"></a>
				
				<a href="#Publications"><img src="./figs/publication_iconv1.png" height="80px" style="margin-bottom:-3px"></a>

				<a href="#Activity"><img src="./figs/activity_iconv1.png" height="80px" style="margin-bottom:-3px"></a>

				<a href="#Teaching"><img src="./figs/teachingv1.png" height="80px" style="margin-bottom:-3px"></a>

				<a href="#Alumni"><img src="./figs/alumniv1.png" height="80px" style="margin-bottom:-3px"></a>

				   
				</p>
			</td>

			<td>
				<img src="./figs/profile.jpg" border="0" width="360"><br>
			</td>

		</tr><tr>
	</tr></tbody>
</table>


</head>

<body>
	

<div id="about">
<p style="text-align:justify";><font face="Georgia">
	I'm an Assistant Professor (<font face="STKaiTi">百人计划研究员</font>) at the College of Computer Science and Technology, <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>, and work closely with Prof <a href="https://person.zju.edu.cn/en/gpan">Gang Pan</a> and Prof <a href="https://person.zju.edu.cn/en/0018196"> Huajin Tang </a>. I received my BEng (2011) and PhD (2017, supervisor: Prof <a href="https://person.zju.edu.cn/en/gpan">Gang Pan</a>) degrees in computer science from <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>. From 2018 to 2022, I was a Research Fellow at the <a href="https://www.ntu.edu.sg/rose">ROSE Lab</a>, Nanyang Technological University and worked closely with Prof <a href="https://camera.pku.edu.cn/">Boxin Shi</a>, Prof <a href="https://personal.ntu.edu.sg/exdjiang/">Xudong Jiang</a>, and Prof <a href="https://personal.ntu.edu.sg/eackot/">Alex Kot</a>.
</font></p>
<p><font face="Georgia">
	I have co-authored 72 peer-reviewed papers, with 15 papers in the IEEE journals and 38 papers in top conferences of CVPR/ICCV/ECCV/NeurIPS/ICML/ICLR/AAAI/IJCAI/MM. I was a recipient of the ACM Rising Star Award (Hangzhou Chapter, 2024) and currently serves as an Associate Editor for <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7274989"> IEEE Transactions on Cognitive and Developmental Systems </a> and <a href="https://www.sciencedirect.com/journal/neurocomputing">Neurocomputing</a>. 
</font></p>
<p><font face="Georgia">
	My research interests include Neuromorphic Computing, Computer vision, Machine Learning, with special emphasis on: Spiking Neural Networks (e.g., training methods, spiking LLM), Neuromorphic Camera (e.g., Event Camera guided low-level vision), Computational Photography (e.g., NeRF, 3DGS, Photometric Stereo)
</font></p>

<p>
	
  
	<font face="STKaiTi" color=#B00E00>  
		<b>常年招收: 博士后、博士、硕士、本科实习生，欢迎邮件联系。希望你：</b>
		<ul>
	  		<li><b>追求：</b>科学严谨的逻辑思维、领域前沿的知识体系、良好的写作表达沟通等习惯</li>
	  		<li><b>认可：</b>文章质量远大于数量、科学研究是关于探索和创造、自己是毕业的第一责任人</li>
	  		<li><b>具备：</b>诚实友善、责任心强、团结主动、乐于交流、独立思考、探索精神、辩证思维的品质</li>
	  		</font>
	  	</ul>
	  </font>
	
</p>

</div>


<h2><font face="Arial" id="News">&#128293 News </font><font size=2>[<a href="https://q-zh.github.io/news" target="_blank">Click to Expand</a>]</font> </h2>
<iframe id="News" src="news.html", width=100%, height=280></iframe>

<h2><font face="Arial" id="Publications">&#128218 Selected Works </font><font size=2>[<a href="https://scholar.google.com/citations?user=ztWK59MAAAAJ" target="_blank">Google Scholar</a>]</font> 
</h2>

<h3 style="margin-top:0px">Neuromorphic Computing: <font color="#000000">Spiking Neural Networks, Event Camera, Brain Data Processing </font></h3> 
<table id="tlayout" width="100%">
		<tr>	
    	<td width="240">
				<img src="./images/ICML25.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td>
				<b>Training High Performance Spiking Neural Network by Temporal Model Calibration </b><br>
				Jiaqi Yan, Changping Wang, De Ma, Huajin Tang, <b>Qian Zheng</b>*, Gang Pan*.<br>
				<em>International Conference on Machine Learning</em> (<i><b>ICML</b></i>), Jul 2025 [<a href="https://icml.cc/virtual/2025/poster/44216">paper</a>][<a href="https://github.com/zju-bmi-lab/TMC">code</a>] (coming soon...)<br>
				<ul>
					<li>Exploit spiking neural networks' temporal heterogeneity through logit gradient analysis</li>
					<li>Highest reported SNN accuracy (up to Jun 2025): <b>85.83%</b> (ImageNet-1K) and <b>87.63±0.15%</b> (CIFAR10-DVS)</li>
				</ul>
			</td>
		</tr>


		<tr>	
    	<td width="240">
				<img src="./images/IJCAI25.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td>
				<b>EDyGS: Event Enhanced Dynamic 3D Radiance Fields from Blurry Monocular Video</b><br>
				Mengxu Lu#, Zehao Chen#, De Ma*, Huajin Tang, <b>Qian Zheng</b>*, Gang Pan.<br>
				<em>International Joint Conference on Artificial Intelligence</em> (<i><b>IJCAI</b></i>), Aug 2025 [<a href="https://github.com/zju-bmi-lab/EDyGS">paper</a>][<a href="https://github.com/zju-bmi-lab/EDyGS">code</a>] (coming soon...)<br>
				<ul>
					<li>Event-enhanced dynamic 3DGS model taking the input of motion-blurred monocular video</li>
					<li>EReconstruct the motion mask field and separate static and dynamic regions</li>
				</ul>
			</td>
		</tr>

		<tr>	
    	<td width="240">
				<img src="./images/AAAI25-yan.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td>
				<b>EvSTVSR: Event Guided Space-Time Video Super-Resolution</b><br>
				Haojie Yan, Zhan Lu, Zehao Chen, De Ma*, Huajin Tang, <b>Qian Zheng</b>*, Gang Pan.<br>
				<em>Proceedings of the Proceedings of the AAAI Conference on Artificial Intelligence</em> (<i><b>AAAI</b></i>), Feb 2025 [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/32983">paper</a>][<a href="https://github.com/hjyyyd/EvSTVSR">code</a>] (coming soon...)<br>
				<ul>
					<li>Event-Guided space-time video super-resolution with fewer adjacent frames</li>
					<li>Excel in handling large motion scenarios</li>
				</ul>
			</td>
		</tr>

		<tr>	
	    	<td width="240">
					<img src="./images/AAAI25-chen2.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>EvHDR-GS: Event-guided HDR Video Reconstruction with 3D Gaussian Splatting</b><br>
					Zehao Chen, Zhanfeng Liao, De Ma, Huajin Tang, <b>Qian Zheng</b>*, Gang Pan*.<br>
					<em>Proceedings of the Proceedings of the AAAI Conference on Artificial Intelligence</em> (<i><b>AAAI</b></i>), Feb 2025 [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/32237">paper</a>][<a href="https://zehaoc.github.io/EvHDR-GS/">code</a>] (coming soon...)<br>
					<ul>
						<li>Ensure consistent brightness for HDR video reconstruction</li>
						<li>Achieve LDR-to-HDR transformation with single-exposure LDR frames</li>
					</ul>
				</td>
			</tr>


		<tr>	
	    	<td width="240">
					<img src="./images/AAAI25-chen1.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>EvHDR-NeRF: Building High Dynamic Range Radiance Fields with Single Exposure Images and Events</b><br>
					Zehao Chen, Zhanfeng Liao, De Ma, Huajin Tang, <b>Qian Zheng</b>*, Gang Pan*.<br>
					<em>Proceedings of the Proceedings of the AAAI Conference on Artificial Intelligence</em> (<i><b>AAAI</b></i>), Feb 2025 [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/32238">paper</a>][<a href="https://zehaoc.github.io/EvHDR-NeRF/">code</a>] (coming soon...)<br>
					<ul>
						<li>Reconstruct HDR radiance field even if input images are degraded and are single-exposured </li>
						<li>Reconstruct Camera Response Function (CRF) from single-exposure images</li>
					</ul>
				</td>
			</tr>

			

		<tr>	
    	<td width="240">
				<img src="./images/NIPS24v1.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td>
				<b>FEEL-SNN: Robust Spiking Neural Networks with Frequency Encoding and Evolutionary Leak Factor</b><br>
				Mengting Xu, De Ma, Huajin Tang, <b>Qian Zheng</b>*, Gang Pan*.<br>
				<em>Conference on Neural Information Processing Systems</em> (<i><b>NeurIPS</b></i>), Dec 2024 [<a href="https://papers.nips.cc/paper_files/paper/2024/file/a73474c359ed523e6cd3174ed29a4d56-Paper-Conference.pdf">paper</a>][<a href="https://github.com/zju-bmi-lab/FEEL_SNN">code</a>]<br>
				<ul>
					<li>A unified framework for SNN robustness analysis</li>
					<li>An inherentrobust SNN method interoperable with other methods, such as adversarial training </li>
				</ul>
			</td>
		</tr>

		<tr>	
    	<td width="240">
				<img src="./images/Arxiv24v1.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td>
				<b>Spiking GS: Towards High-Accuracy and Low-Cost Surface Reconstruction via Spiking Neuron-based Gaussian Splatting</b><br>
				Weixing Zhang#, Zongrui Li#, De Ma, Huajin Tang, Xudong Jiang, <b>Qian Zheng</b>*, Gang Pan.<br>
				<em>arXiv preprint arXiv:2410.07266</em> (<i><b>Arxiv</b></i>), Oct 2024 [<a href="https://arxiv.org/abs/2410.07266">paper</a>][<a href="https://github.com/zju-bmi-lab/SpikingGS">code</a>]<br>
				<ul>
					<li>Spiking neuron to reduce excessive Gaussians</li>
					<li>Faster, lower storage, and higher accuracy 3DGS-based surface reconstruction</li>
					<li><b>Stable performance superiority</b> of bio-inspired neural computation over artificial neuron-based computation on core AI tasks</li>
				</ul>
			</td>
		</tr>

		<tr>	
	    	<td width="240">
					<img src="./images/MM24.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Event-ID: Intrinsic Decomposition Using an Event Camera</b><br>
					Zehao Chen#, Zhan Lu#, De Ma, Huajin Tang, <b>Qian Zheng</b>*, Gang Pan*.<br>
					<em>ACM International Conference on Multimedia</em> (<i><b>MM</b></i>), Oct 2024 [<a href="https://dl.acm.org/doi/10.1145/3664647.3681133">paper</a>][<a href="https://zehaoc.github.io/Event-ID//">code</a>] (coming soon...)<br>
					<ul>
						<li>Event-based model establishes relationship between events and intrinsic components </li>
						<li>Multi-view consistency of events to extract specular-related clues</li>
						<li>Event-guided intrinsic decomposition framework enables relighting under extreme conditions</li>
					</ul>
				</td>
			</tr>

		<tr>	
    	<td width="240">
				<img src="./images/AAAI24-liaov1.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td>
				<b>Spiking NeRF: Representing the Real-World Geometry by a Discontinuous Representation</b><br>
				Zhanfeng Liao, Yan Liu, <b>Qian Zheng</b>*, Gang Pan*.<br>
				<em>Proceedings of the Proceedings of the AAAI Conference on Artificial Intelligence</em> (<i><b>AAAI</b></i>), Feb 2024 <b>(Oral)</b> [<a href="https://dl.acm.org/doi/10.1609/aaai.v38i12.29285">paper</a>][<a href="https://github.com/zju-bmi-lab/SpikingNeRF">code</a>][<a href="https://valser.org/article-820-1.html" target="_blank">VALSE<font face="STKaiTi">论文速览</font></a>]<br>
				<ul>
					<li>An ANN-SNN hybrid MLP for NeRF-based 3D surface reconstruction</li>
					<li>Demonstrate the superiority of spiking neuron on 3D surface representation</li>
					<li><b>Stable performance superiority</b> of bio-inspired neural computation over artificial neuron-based computation on core AI tasks</li>
				</ul>
			</td>
		</tr>


			<tr>	
    	<td width="240">
				<img src="./images/TPAMI23-hu.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td>
				<b>Fast-SNN: Fast Spiking Neural Network by Converting Quantized ANN </b><br>
				Yangfan Hu#, <b>Qian Zheng</b>#, Xudong Jiang, Gang Pan*.<br>
				<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<i><b>TPAMI</b></i>), Vol. 45, No. 12, Dec 2023 [<a href="https://arxiv.org/abs/2305.19868">paper</a>][<a href="https://github.com/zju-bmi-lab/Fast-SNN">code</a>]<br>
				<ul>
					<li>An ANN2SNN conversion method with high performance and low time step</li>
					<li>Highest reported SNN accuracy (up to Jun 2025): object detection (mAP: <b>73.43%</b>, time steps: 7, PASCAL VOC 2007), and semantic segmentation (mIoU: <b>69.7%</b>, time steps: 15, PASCAL VOC 2012)</li>
				</ul>
			</td>
		</tr>

		<tr>	
    	<td width="240">
				<img src="./images/NIPS23v1.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td>
				<b>Alleviating the Semantic Gap for Generalized fMRI-to-Image Reconstruction</b><br>
				Tao Fang, <b>Qian Zheng</b>*, Gang Pan.<br>
				<em>Conference on Neural Information Processing Systems</em> (<i><b>NeurIPS</b></i>), Dec 2023 <b>(Spotlight, 378/12343)</b> [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/3106c718fe84b91fc301fe2f5b738448-Paper-Conference.pdf">paper</a>][<a href="hhttps://github.com/duolala1/GESS">code</a>]<br>
				<ul>
					<li>Alleviate the semantic gap within known and unknown semantic subspaces</li>
					<li>A generalized fMRI-to-image reconstruction method that adaptively weights the semantic and structural information</li>
				</ul>
			</td>
		</tr>

		<tr>	
	    	<td width="240">
					<img src="./images/CVPR21.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Indoor Lighting Estimation using an Event Camera</b><br>
					Zehao Chen#, <b>Qian Zheng</b>#, Peisong Niu, Huajin Tang, Gang Pan*.<br>
					<em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), Jun 2021 [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Indoor_Lighting_Estimation_Using_an_Event_Camera_CVPR_2021_paper.pdf">paper</a>][<a href="">code</a>](coming soon...)<br>
					<ul>
						<li>Event camera captures environmental dynamics during light-activation transients </li>
						<li>Alleviate illumination-distance ambiguity from the inverse-square law in optical imaging</li>
						<li>First attempt to build reflectance model using event streams</li>
					</ul>
				</td>
			</tr>

</table>




<!-- <h3 style="margin-top:5px"><font color="#123580">Brain-Relevant Data:</font> Brain Signals and Event Streams</h3> 
<table id="tlayout" width="100%">

		





		

			

	</table>


 -->

		<h3 style="margin-top:0px">Stereo Vision: <font color="#000000">Photometric Stereo, NeRF, 3DGS</font></h3> 
		<table id="tlayout" width="100%">
			<tr>	
	    	<td width="240">
					<img src="./images/TPAMI25.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Revisiting Supervised Learning-Based Photometric Stereo Networks</b><br>
					Xiaoyao Wei, Zongrui Li*, Binjie Ding, Boxin Shi, Xudong Jiang, Gang Pan, Yanlong Cao*, <b>Qian Zheng</b>*<br>
					<em>IEEE Transactions on Pattern Analysis and Machine Intelligence </em> (<i><b>TPAMI</b></i>), Apr 2025 [<a href="https://ieeexplore.ieee.org/document/10948383">paper</a>][<a href="https://github.com/wxy-zju/ESSENCE-Net">code</a>][<a href="https://mp.weixin.qq.com/s/KgD0CBmAIwcAlwEvNGBb2g" target="_blank"><font face="STKaiTi">推文</font></a>]<br>
					<ul>
						<li>Answer three fundamental questions: 1) Waht is the desired deep feature? 2) How to resolve PS challenges? 3) What is the desired network architecture? </li>
						<li>A solution based on answers that achieves SOTA performance on several PS benchmarks</li>
					</ul>
				</td>
			</tr>

			<tr>	
	    	<td width="240">
					<img src="./images/CVPR24.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Spin-UP: Spin Light for Natural Light Uncalibrated Photometric Stereo</b><br>
					Zongrui Li#, Zhan Lu#, Haojie Yan, Boxin Shi, Gang Pan, <b>Qian Zheng</b>*, Xudong Jiang<br>
					<em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), Jun 2024 [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Spin-UP_Spin_Light_for_Natural_Light_Uncalibrated_Photometric_Stereo_CVPR_2024_paper.pdf">paper</a>][<a href="https://github.com/LMozart/CVPR2024-SpinUP">code</a>]<br>
					<ul>
						<li>A novel setup for Natural Light Uncalibrated Photometric Stereo</li>
						<li>A light prior that leverages object's occluding boundaries for reliable environment light</li>
					</ul>	
				</td>
			</tr>

			<tr>	
	    	<td width="240">
					<img src="./images/CVPR23v1.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>DANI-Net: Uncalibrated Photometric Stereo by Differentiable Shadow Handling, Anisotropic Reflectance Modeling, and Neural Inverse Rendering</b><br>
					Zongrui Li, <b>Qian Zheng</b>*, Boxin Shi, Gang Pan,  Xudong Jiang<br>
					<em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), Jun 2023 [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Li_DANI-Net_Uncalibrated_Photometric_Stereo_by_Differentiable_Shadow_Handling_Anisotropic_Reflectance_CVPR_2023_paper.pdf">paper</a>][<a href="https://github.com/LMozart/CVPR2023-DANI-Net">code</a>]<br>
					<ul>
						<li>A differentiable shadow handling method and an anisotropic reflectance model</li>
						<li>A self-supervised framework that simultaneously optimizes shape, anisotropic reflectance, shadow map, and light conditions</li>
					</ul>	
				</td>
			</tr>

			<tr>	
	    	<td width="240">
					<img src="./images/AAAI24-luv1.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Pano-NeRF: Synthesizing High Dynamic Range Novel Views with Geometry from Sparse Low Dynamic Range Panoramic Images</b><br>
					Zhan Lu, <b>Qian Zheng</b>*, Boxin Shi, Xudong Jiang<br>
					<em>Proceedings of the Proceedings of the AAAI Conference on Artificial Intelligence</em> (<i><b>AAAI</b></i>), Feb 2024 [<a href="https://arxiv.org/abs/2312.15942">paper</a>][<a href="https://github.com/Lu-Zhan/Pano-NeRF">code</a>]<br>
					<ul>
						<li>An interesting idea of the proposed irradiance fields</li>
						<li>Irradiance fields can be integrated into and jointly optimized with radiance fields to recover the geometry and HDR of a panoramic image</li>
					</ul>	
				</td>
			</tr>

			<tr>	
	    	<td width="240">
					<img src="./images/ICCV19.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>SPLINE-Net: Sparse Photometric Stereo through Lighting Interpolation and Normal Estimation Networks</b><br>
					<b>Qian Zheng</b>#*, Yiming Jia#, Boxin Shi*, Xudong Jiang, Ling-Yu Duan, Alex C. Kot<br>
					<em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em> (<i><b>ICCV</b></i>), Oct 2019 [<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Zheng_SPLINE-Net_Sparse_Photometric_Stereo_Through_Lighting_Interpolation_and_Normal_Estimation_ICCV_2019_paper.pdf">paper</a>][<a href="https://github.com/yiming-j/SPLINE-Net">code</a>]<br>
					<ul>
						<li>Sparse photometric stereo by generation</li>
						<li>Convert insights of global illumination effects and isotropic reflectance to loss fuction based on <a href="https://arxiv.org/abs/1808.10093">observation map</a></li>
					</ul>	
				</td>
			</tr>

			<tr>	
	    	<td width="240">
					<img src="./images/TIP19.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Numerical Reflectance Compensation for Non-Lambertian Photometric Stereo</b><br>
					<b>Qian Zheng</b>, Ajay Kumar*, Boxin Shi, Gang Pan<br>
					<em> IEEE Transactions on Image Processing </em> (<i><b>TIP</b></i>), Vol 28, Iss 7, Jul 2019) [<a href="https://ieeexplore.ieee.org/document/8625481">paper</a>][<a href="https://github.com/q-zh/numerical-ps">code</a>]<br>
					<ul>
						<li>Reformulate non-Lambertian photometric stereo problem using the angular error to close the gap between evaluation and optimization</li>
						<li>Numerical compensation scheme that solves photometric stereo problem by minizing the angular error</a> </li>
					</ul>	
				</td>
			</tr>


		</table>




	  <h3 style="margin-top:0px"><font color="#123580">Visual Generation, Reinformance Learning, and Computational Photography</font></h3> 
		<table id="tlayout" width="100%">

			<tr>	
	    	<td width="240">
					<img src="./images/ECCV24.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Connecting Consistency Distillation to Score Distillation for Text-to-3D Generation</b><br>
					Zongrui Li#, Minghui Hu#, <b>Qian Zheng</b>*, Xudong Jiang.<br>
					<em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>), Sep 2024 [<a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05982.pdf">paper</a>][<a href="https://github.com/LMozart/ECCV2024-GCS-BEG">code</a>]<br>
					<ul>
						<li>Identify 3 problems in the PF-ODEs-based score distillation method by connecting consistency distillation to score distillation</li>
						<li>An improved score distillation method to enhance details and fidelity of generated 3D assets</li>
					</ul>	
				</td>
			</tr>

			<tr>	
	    	<td width="240">
					<img src="./images/AAAI24-guo.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Learning to Manipulate Artistic Images</b><br>
					Wei Guo#, Yuqi Zhang#, De Ma*, <b>Qian Zheng</b>*<br>
					<em>Proceedings of the AAAI Conference on Artificial Intelligence</em> (<i><b>AAAI</b></i>), Feb 2024 [<a href="https://arxiv.org/abs/2401.13976">paper</a>][<a href="https://github.com/SnailForce/SIM-Net">code</a>][<a href="https://valser.org/article-823-1.html">VALSE<font face="STKaiTi">论文速览</font></a>]<br>
					<ul>
						<li>An <b>arbitrary</b> Style Image Manipulation Network to achieve zero-shot style image manipulation</li>
						<li>Balance computational efficiency and high resolution</li>
					</ul>	
				</td>
			</tr>


			<tr>	
	    	<td width="240">
					<img src="./images/ICLR25v1.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Mitigating Reward Over-Optimization in RLHF via Behavior-Supported Regularization</b><br>
					Juntao Dai, Taiye Chen, Yaodong Yang*, <b>Qian Zheng</b>*, Gang Pan<br>
					<em>International Conference on Learning Representations</em> (<i><b>ICLR</b></i>), Apr 2025 [<a href="https://arxiv.org/abs/2503.18130">paper</a>]<br>
					<ul>
						<li>Enable the detection of whether a response is OOD for the reward model.</li>
						<li>The first method that uses value regularization to address reward over-optimization and penalizes OOD values without affecting ID ones</li>
					</ul>	
				</td>
			</tr>

			<tr>	
	    	<td width="240">
					<img src="./images/ICML24.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Safe Reinforcement Learning using Finite-Horizon Gradient-based Estimation</b><br>
					Juntao Dai, Yaodong Yang, <b>Qian Zheng</b>*, Gang Pan*<br>
					<em>International Conference on Machine Learning</em> (<i><b>ICML</b></i>), Jul 2024 [<a href="https://arxiv.org/abs/2412.11138">paper</a>]<br>
					<ul>
						<li>A method to estimate finite-horizon non-discounted constraints in Safe RL tasks</li>
						<li>A deep Safe RL algorithm to address tasks with finite-horizon constraints</li>
					</ul>	
				</td>
			</tr>

			<tr>	
	    	<td width="240">
					<img src="./images/AAAI23-dai.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Augmented Proximal Policy Optimization for Safe Reinforcement Learning</b><br>
					Juntao Dai#, Jiaming Ji#, Long Yang, <b>Qian Zheng</b>*, Gang Pan*<br>
					<em>Proceedings of the AAAI Conference on Artificial Intelligence</em> (<i><b>AAAI</b></i>), Feb 2023 [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/25888">paper</a>]<br>
					<ul>
						<li>Construct multiplier-penalty function that dampens cost oscillation for stable convergence while being equivalent to the primal constrained problem to precisely control safety costs</li>
						<li>Provide an implementation based above construction</li>
					</ul>	
				</td>
			</tr>

			<tr>	
	    	<td width="240">
					<img src="./images/CVPR21-zheng.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Single Image Reflection Removal with Absorption Effect</b><br>
					<b>Qian Zheng</b>*, Boxin Shi*, Jinnan Chen, Xudong Jiang, Ling-Yu Duan, Alex C. Kot<br>
					<em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), Jun 2021 [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Single_Image_Reflection_Removal_With_Absorption_Effect_CVPR_2021_paper.pdf">paper</a>][<a href="https://github.com/q-zh/absorption">code</a>]<br>
					<ul>
						<li>Reflection-contaminated image formation model considering absorption effect</li>
						<li>Superior performance advantage on the recovery of overall intensity</li>
					</ul>	
				</td>
			</tr>

			<tr>	
	    	<td width="240">
					<img src="./images/CVPR21-hong.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>Panoramic Image Reflection Removal</b><br>
					Yuchen Hong#, <b>Qian Zheng</b>#, Lingran Zhao, Xudong Jiang, Alex C. Kot, Boxin Shi*<br>
					<em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), Jun 2021 [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_Panoramic_Image_Reflection_Removal_CVPR_2021_paper.pdf">paper</a>]<br>
					<ul>
						<li>Relieve the content ambiguity for reflection removal using a panoramic image</li>
						<li>Solve the geometric and photometric misalignment between reflection scenes in panoramic and glass-reflected views</li>
						<li>Generalizes well to casual users without panoramic cameras</li>
					</ul>	
				</td>
			</tr>

			<tr>	
	    	<td width="240">
					<img src="./images/CVPR20.png" width="210px" height = auto style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td>
					<b>What does Plate Glass Reveal about Camera Calibration?</b><br>
					<b>Qian Zheng</b>*, Jinnan Chen, Zhan Lu, Boxin Shi*, Xudong Jiang, Kim-Hui Yap, Ling-Yu Duan, and Alex C. Kot<br>
					<em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), Jun 2020 [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Zheng_What_Does_Plate_Glass_Reveal_About_Camera_Calibration_CVPR_2020_paper.pdf">paper</a>][<a href="https://github.com/q-zh/GlassCalibration">code</a>]<br>
					<ul>
						<li>First work addresses the single image camera calibration problem <b>in the context of glass reflection</b></li>
						<li>320 reflection-contaminated images with their calibration parameters</li>
						<li>Alleviate the ill-posedness of single image panoramic image estimation</li>
					</ul>	
				</td>
			</tr>



		</table>




<h2><font face="Arial" id="Activity">&#127759 Activities </font></h2>


<dl>
    <dt>Associate Editor</dt>
    <dd>IEEE Transactions on Cognitive and Developmental Systems (2024.12 - present)</dd>
    <dd>Neurocomputing (2023.10 - present)</dd>

    <dt>Reviewer</dt>
    <dd>TPAMI, IJCV, TIP, TNNLS, TCSVT, TMM</dd>
    <dd>CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR, SIGGRAPH, AAAI, IJCAI, ACM MM</dd>

    <dt>Committee Member</dt>
    <dd>Finance Chair: <a href="https://www.cis-ram.org/2024/" target="_blank"> IEEE CIS-RAM 2024</a></dd>
    <dd>The Branch of Consciousness Science of the Chinese Cognitive Science Society (<font face="STKaiTi">中国认知科学学会意识科学分会委员</font>)</dd>
    <dd>Young Professionals Committee of Chinese Association for Artificial Intelligence (<font face="STKaiTi">中国人工智能协会青年工作委员会委员</font>)</dd>
    <dd>The Branch of Brain-computer Interface & Interaction of Chinese Neuroscience Society (<font face="STKaiTi">中国神经科学学会脑机分会委员</font>) </dd>


</dl>







<h2><font face="Arial" id="Teaching">&#128198 Teaching </font></h2>
<dl>
    <dt>Theory of Computation (Undergraduate)</dt>
    <dd>2024-2025 Fall&Winter, Zhejiang University</dd>
    <dd>2023-2024 Fall&Winter, Zhejiang University</dd>

    <dt>Machine Learning (Graduate)</dt>
    <dd>2023-2024 Summer, Zhejiang University</dd>
    <dd>2022-2023 Summer, Zhejiang University</dd>
</dl>

<h2><font face="Arial" id="Alumni">&#127891 Alumni </font></h2>

<dl>
		<dt><a href="https://github.com/calico-1226">Juntao Dai</a> (PhD Student, 2025.06)</dt>
		<dd>Co-supvervised with Prof Gang Pan</dd>
		<dd>During his doctoral studies, we published papers at AAAI 2023, ICML 2025, and ICLR 2025</dd>
		<dd>Upon graduation, Juntao joined <a href="https://www.baai.ac.cn/about-us">Beijing Academy of Artificial Intelligence (BAAI)</a></font></dd>

		
		<dt><a href="https://scholar.google.com/citations?user=jQ4ezKoAAAAJ&hl">Zehao Chen</a> (PhD Student, 2024.12)</dt>
		<dd>Upon graduation, Zehao continued to work in my group as postdoc (postdoc PIs: Prof Gang Pan and Prof Zengwei Zheng)</dd>
		<!-- <dd>During his doctoral studies, we published papers at CVPR 2021, ACM MM 2024, and AAAI 2025 * 2</dd> -->
		<!-- <dd>Upon graduation, Zehao was under <a href="https://www.hzcu.edu.cn/rczp/rczp/bshzpgg/zpgw.htm">ZJUCC-ZJU Joint Postdoctoral Fellowship program</a> (2025.04)</dd> -->
		<dd>During his doctoral studies, Zehao won Hangzhou Innovation and Entrepreneurship Competition</a> (3rd Prize, 7.9%)</dd>
		<dd>Zehao was awarded Postdoctoral Innovation Talent Support Program (<font color=blue face="STKaiTi"><b>博新计划</b></font>)</dd>
		<!-- <dd>Zehao was secured the General Program from China Postdoctoral Science Found (<font color=blue face="STKaiTi" ><b>博后面上项目</b></font>)</dd> -->
		
		<dt><a href="https://scholar.google.com/citations?user=Gi9QuygAAAAJ&hl">Tao Fang</a> (PhD Student, 2024.03)</dt>
		<dd>Co-supvervised with Prof Gang Pan and Prof Yu Qi</dd>
		<dd>During his doctoral studies, we published papers at AAAI 2023 and NeurIPS 2023</dd>
		<dd>All publications during his doctoral studies were either oral (NeurIPS 2021, AAAI 2023) or spotlight (NeurIPS 2023)</dd>
		<dd>Upon graduation, Tao Fang joined <a href="https://www.alibabacloud.com/tc?_p_lc=2">Alibaba Cloud</a></dd>


		<dt><a href="https://dxing-cs.github.io/">Dong Xing</a> (PhD Student, 2023.12)</dt>
		<dd>Co-supvervised with Prof Gang Pan and Prof Bo An</dd>
		<dd>During his doctoral studies, we published papers at IJCAI 2021 (oral), IJCAI 2022 (oral), and ICML 2023</dd>
		<dd>Upon graduation, Dong Xing joined <a href="https://optiver.com/">Optiver</a></dd>


		<dt><a href="https://info.zufe.edu.cn/szdw/js2/hyf1/grjj1.htm">Yangfan Hu</a> (PhD Student, 2023.06)</dt>
		<dd>Co-supvervised with Prof Gang Pan</dd>		
		<dd>During his doctoral studies, we published papers at TPAMI 2023 and TCDS 2024</dd>
		<dd>Upon graduation, Yangfan joined <a href="https://english.zufe.edu.cn/">Zhejiang University of Finance and Economics</a> as a faculty</dd>


		<!--Master Student -->
		<dt><a href="">Zhanfeng Liao</a> (Master Student, 2024.03)</dt>
    <dd>Co-supvervised with Prof Gang Pan.</dd>
    <dd>During his undergraduate studies, we published a paper at AAAI 2024 (oral)</dd>
   	<dd>Upon graduation, Zhanfeng pursued PhD degree at Tsinghua University, supervised by Prof Yebin Liu</dd>

		<dt><a href="">Junzhou Chen</a> (Master Student, 2024.03)</dt>
		<dd>Co-supvervised with Prof Gang Pan.</dd>
    <dd>Upon graduation, Junzhou joined <a href="https://zrzyj.wenzhou.gov.cn/">Wenzhou Bureau of Natural Resources and Planning</a></dd>


		<dt><a href="https://scholar.google.com/citations?user=7FlkVy8AAAAJ">Yuqi Zhang</a> (Master Student, 2023.03)</dt>
		<dd>Co-supvervised with Prof Gang Pan</dd>
		<dd>During her undergraduate studies, we published a paper at CICAI 2022, our follow-up work published at AAAI 2024</dd>
    <dd>Upon graduation, Yuqi joined <a href="https://www.bytedance.com/">ByteDance</a></dd>

    <!-- Graduate Student-->

    <dt><a href="">Zhiyuan Ma</a> (Undergraduate Student, 2025.06)</dt>
		<dd>Zhiyuan was awarded 2025 Excellent Undergraduate Dissertation of Zhejiang University</dd>
		<dd>Upon graduation, Zhiyuan pursued PhD degree at Tsinghua University, supervised by Prof Sen Song</dd>

</dl>




 
<div id="footer">
	<div id="footer-text"></div>
<center><table>
	<tbody>
	<tr>
  <td height="10"><a href='https://mapmyvisitors.com/web/1byjb'  title='Visit tracker'><img height="150" src='https://mapmyvisitors.com/map.png?cl=f29732&w=a&t=tt&d=uUdLrZR0NKMblnjNtlWdR-fMINyxwR0BMItLirFURig&co=d3f5ff&ct=050000'/></a></td>
  <!-- <script type="text/javascript" id="mmvst_globe" src="//mapmyvisitors.com/globe.js?d=xCm9v2NbyIyGPcvPXuQSGoE7SXjh85Oy-KAGvR2nWgg"></script> -->
	</tr>
	</tbody>
</table></center>
<p><center><font face="Arial">
        <br>
            &copy; Qian Zheng (Established: Jun 2025) | Last updated: Jun 29 2025
        </font></center></p>
</div>

<!-- <script>
  let iframe = document.getElementById('News');
  let iframeDocument = iframe.contentDocument || iframe.contentWindow.document; //兼容IE

  // 等待iframe内容加载完成
  iframe.onload = function() {
    let links = iframeDocument.querySelectorAll('a');
    for (let i = 0; i < links.length; i++) {
      links[i].style.color = 'red'; // 或者其他颜色值
    }
  };
</script> -->


</body></html>
