<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Qian Zheng, PH, ZJU, Zhejiang University"> 
<meta name="description" content="Qian Zheng's homepage">
<!-- <meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" /> -->
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Qian Zheng's homepage, Zhejiang University</title>
<script>
  // (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  // (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  // m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  // })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  // ga('create', 'UA-87320911-1', 'auto');
  // ga('send', 'pageview');
  $(function(){
  	$('#about').load('./pages/about.html');
  })
</script>
</head>
<body>
	 <!-- <link rel="import" href="./pages/about.html" id="page1"/> -->
	 
<div id="about">


	
<!-- <div id="news"></div>
<div id="publication"></div>
<div id="activity"></div>
 -->
<!-- 
<h2><font face="Arial"> News </font></h2>
<ul style="list-style-type:none">
   <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3">
      [May 2025] Thrilled that my student received Outstanding Bachelor's Graduation Project Award (only 1.7%) of Hangzhou Dianzi University under my supervision! <br>
      [May 2025] I start my work as a Postdoctoral Fellow at Zhejiang University <br>
      [Mar 2025] Awarded the 2024 Annual Assessment Outstanding Faculty Award of School of Communication Engineering <br>
      [Mar 2025] I obtain the open fund from the "Key Laboratory of Equipment and Informatization in Environment Controlled Agriculture, Ministry of Agriculture and Rural Affairs" <br>
      [Dec 2024] One paper accepted by <i>IEEE TMI</i> <br>
      [Nov 2024] One paper accepted by <i>COMPAG</i> <br>
      [Sep 2024] I attend <i>ECPLF2024</i> and give an oral report in Bologna, Italy <br>
      [Aug 2024] I obtain the Young Scientists Fund of the National Natural Science Foundation of China (国家自然科学基金青年科学基金项目) <br>
      [Jun 2024] One paper accepted by <i>SIViP</i> <br>
      [Feb 2024] Four papers accepted by <i>ECPLF2024</i> as oral presentation <br>
      [Dec 2023] One paper accepted by <i>ANIMALS</i> <br>
      [Dec 2023] I join Hangzhou Dianzi University as a faculty <br>
      ------------------------------------------------------------<br>
      [Oct 2023] I officially graduate from CityU <br>
      [Sep 2023] One paper accepted by <i>COMPAG</i> <br>
      [Jul 2023] I pass the Ph.D. oral defence <br>
      [Jul 2023] One paper accepted by <i>COMPAG</i> <br>
      [May 2023] One paper accepted by <i>COMPAG</i> <br>
      [Apr 2023] One paper accepted by <i>COMPAG</i> <br>
      [Apr 2023] One paper accepted by <i>ISAEW2023</i> as oral presentation <br>
      [Sep 2022] Two papers accepted by <i>USPLF2023</i> as oral presentation <br>
      [Sep 2022] Research Tuition Scholarship (RTS) in City University of Hong Kong <br>
      [Aug 2022] One paper accepted by <i>ANIMALS</i> <br>
      [Jun 2022] One paper accepted by <i>COMPAG</i> <br>
      [May 2022] One paper accepted by <i>J.R.Soc.Interface</i> <br>
      [Apr 2022] Three papers accepted by <i>ECPLF2022</i> as oral presentation <br>
      [Oct 2021] Outstanding Graduate Student Paper and Presentation Award at <i>ISAEW2021</i>  <br>
      [Oct 2021] One paper accepted by <i>COMPAG</i> <br>
      [Sep 2021] One paper accepted by <i>SENSORS</i> <br>
      [Jul 2021] One paper accepted by <i>ASABE2021</i> <br>
      [Apr 2021] Two papers accepted by <i>ISAEW2021</i> as oral presentation <br>
      [Oct 2020] One paper accepted by <i>ACPLF2020</i> <br>
      [Oct 2019] I join Prof. Liu's lab as a Ph.D. student <br>
   </font></p>
</ul>



<h2><font face="Arial"> Publications </font> [<a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=Wu9cCvAAAAAJ">Google Scholar</a>]</h2>

<table id="tbPublications" width="100%">
	<body>
    <tr><h3><font face="Arial"> Journal Papers </font></h3> </tr>
		
    <tr>	
	    	<td width="206">
		<img src="./Figs/DEeR.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>DEeR: Deviation Eliminating and Noise Regulating for Privacy-preserving Federated Low-rank Adaptation</b> <br>
		Meilu Zhu, <b>Axiu Mao</b>, Jun Liu*, Yixuan Yuan*.<be>
		<p><em>IEEE Transactions on Medical Imaging</em> (<i><b>TMI</b></i>), Dec, 2024 <br>
	        [<a href="https://ieeexplore.ieee.org/abstract/document/10807365">paper</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>

		
    <tr>	
	    	<td width="206">
		<img src="./Figs/zheng.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Characterization of social cohesion status of pre-weaning piglets based on lightweight pose estimation</b> <br>
		Zheng He, Chuanyi Guo, Zhaojin Guo, Li Lyu, Endai Huang, <b>Axiu Mao</b>, Kai Liu*.<be>
		<p><em>Computers and Electronics in Agriculture</em> (<i><b>COMPAG</b></i>), Dec, 2024 <br>
	        [<a href="https://www.sciencedirect.com/science/article/pii/S0168169924011074?dgcid=coauthor">paper</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>

		
    <tr>	
	    	<td width="206">
		<img src="./Figs/SCA-ConvNet.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Estimation of cattle weight from composite image/height/length data with spatial and channel attention convolution network (SCA-ConvNet)</b> <br>
		Leibin Lan, Lei Shen*, Huaxia Wang, Yudong Yao, Peng Zheng, <b>Axiu Mao</b>.<br>
		<p><em>Signal, Image and Video Processing</em>, Sep, 2024 <br>
	        [<a href="https://link.springer.com/article/10.1007/s11760-024-03398-5">paper</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>		
		
    <tr>	
	    	<td width="206">
		<img src="./Figs/Pigeon.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Automatic Detection of Feral Pigeons in Urban Environments Using Deep Learning</b> <br>
		Zhaojin Guo, Zheng He, Li Lyu, <b>Axiu Mao</b>, Endai Huang, Kai Liu*.<br>
		<p><em>Animals</em>, Jan, 2024 <br>
	        [<a href="https://www.mdpi.com/2076-2615/14/1/159">paper</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
		
    <tr>	
	    	<td width="206">
		<img src="./Figs/T2S-IR.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>A Teacher-to-Student Information Recovery Method Toward Energy-Efficient Animal Activity Recognition at Low Sampling Rates</b> <br>
		<b>Axiu Mao</b>, Mei Zhu, Endai Huang, Xi Yao, Kai Liu*.<br>
		<p><em>Computers and Electronics in Agriculture</em> (<i><b>COMPAG</b></i>), Sep, 2023 <br>
	        [<a href="https://www.sciencedirect.com/science/article/pii/S0168169923006300?dgcid=coauthor">paper</a>][<a href="https://github.com/Max-1234-hub/T2S-IR">code</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
		
    <tr>	
	    	<td width="206">
		<img src="./Figs/review.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Deep Learning-based Animal Activity Recognition with Wearable Sensors: Overview, Challenges, and Future Directions</b> <br>
		<b>Axiu Mao</b>, Endai Huang, Xiaoshuai Wang, Kai Liu*.<br>
		<p><em>Computers and Electronics in Agriculture</em> (<i><b>COMPAG</b></i>), Jul, 2023 <br>
	        [<a href="https://www.sciencedirect.com/science/article/pii/S0168169923004313?dgcid=coauthor#f0005">paper</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>

    <tr>	
	    	<td width="206">
		<img src="./Figs/CClusnet_Inseg.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Occlusion-Resistant Instance Segmentation of Piglets in Farrowing Pens Using Center Clustering Network</b> <br>
		Endai Huang, <b>Axiu Mao</b>, Junhui Hou, Yongjian Wu, Weitao Xu, Maria Camila Ceballos, Thomas D. Parsons, Kai Liu*.<br>
		<p><em>Computers and Electronics in Agriculture</em> (<i><b>COMPAG</b></i>), May, 2023 <br>
		[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0168169923003381?dgcid=coauthor">paper</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
		
   <tr>	
	    	<td width="206">
		<img src="./Figs/AISGAN.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>A Semi-supervised Generative Adversarial Network for Amodal Instance Segmentation of Piglets in Farrowing Pens</b> <br>
		Endai Huang, Zheng He, <b>Axiu Mao</b>, Maria Camila Ceballos, Thomas D. Parsons, Kai Liu*.<br>
		<p><em>Computers and Electronics in Agriculture</em> (<i><b>COMPAG</b></i>), Apr, 2023 <br>
		[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0168169923002272">paper</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
			
    <tr>	
	    	<td width="206">
		<img src="./Figs/FedAAR.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>FedAAR: A Novel Federated Learning Framework for Animal Activity Recognition with Wearable Sensors</b> <br>
		<b>Axiu Mao</b>, Endai Huang, Haiming Gan, Kai Liu*.<br>
		<p><em>Animals</em>, Aug, 2022 <br>
		[<a href="https://www.mdpi.com/2076-2615/12/16/2142">paper</a>][<a href="https://github.com/Max-1234-hub/FedAAR">code</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
		
    <tr>	
	    	<td width="206">
		<img src="./Figs/Gan.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Automated Detection and Analysis of Piglet Suckling Behaviour Using High-accuracy Amodal Instance Segmentation</b> <br>
		Haiming Gan, Mingqiang Ou, Chengpeng Li, Xiarui Wang, Jingfeng Guo, <b>Axiu Mao</b>, Maria Camila Ceballos, Thomas D. Parsons, Kai Liu*, Yueju Xue*.<br>
		<p><em>Computers and Electronics in Agriculture</em> (<i><b>COMPAG</b></i>), Aug, 2022 <br>
		[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0168169922004793">paper</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
		
    <tr>	
		<td width="206">
		<img src="./Figs/Light-VGG11.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Automated Identification of Chicken Distress Vocalizations Using Deep Learning Models</b> <br>
		<b>Axiu Mao</b>, Claire S. E. Giraudet, Kai Liu*, Inês De Almeida Nolasco, Zhiqin Xie, Zhixun Xie, Yue Gao, James Theobald, Devaki Bhatta, Rebecca Stewart, Alan G. McElligott*.<br>
		<p><em>Journal of Royal Society Interface</em> (<i><b>J.R.Soc.Interface</b></i>), Jun, 2022 <br>
		[<a href="https://royalsocietypublishing.org/doi/10.1098/rsif.2021.0921">paper</a>][<a href="https://github.com/Max-1234-hub/light-VGG11">code</a>][<a href="https://www.scimex.org/newsfeed/algorithm-almost-im-peck-able-at-picking-up-chicken-distress-calls/">newsletters</a>][<a href="https://www.science.org/content/article/artificial-intelligence-could-spot-baby-chickens-distress">newsletters</a>][<a href="https://www.theguardian.com/science/2022/jun/29/ai-could-improve-welfare-of-farmed-chickens-by-listening-to-their-squawks">newsletters</a>][<a href="https://www.newscientist.com/article/2326521-ai-that-detects-chicken-distress-calls-could-improve-farm-conditions/">newsletters</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr> 
		
    <tr>	
		<td width="206">
		<img src="./Figs/CClusnet.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Center Clustering Network Improves Piglet Counting Under Occlusion</b> <br>
		Endai Huang, <b>Axiu Mao</b>, Haiming Gan, Maria Camila Ceballos, Thomas D. Parsons, Yueju Xue, Kai Liu*.<br>
		<p><em>Computers and Electronics in Agriculture</em> (<i><b>COMPAG</b></i>), Oct, 2021 <br>
	        [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0168169921004348?dgcid=coauthor">paper</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
		
    <tr>	
		<td width="206">
		<img src="./Figs/CMI-Net.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Cross-Modality Interaction Network for Equine Activity Recognition Using Imbalanced Multi-Modal Data</b> <br>
		<b>Axiu Mao</b>, Endai Huang, Haiming Gan, Rebecca S. V. Parkes, Weitao Xu, Kai Liu*.<br>
		<p><em>Sensors</em>, Sep, 2021 <br>
	        [<a href="https://www.mdpi.com/1424-8220/21/17/5818">paper</a>][<a href="https://github.com/Max-1234-hub/CMI-Net">code</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>

<table id="tbPublications" width="100%">
    <tr><h3><font face="Arial"> Conference Papers </font></h3> </tr>		
    <tr>	
	    	<td width="206">
		<img src="./Figs/GF.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Cross-species knowledge sharing for improved animal activity recognition with limited labelled data</b> <br>
		<b>Axiu Mao</b>, Meilu Zhu, Endai Huang, Zhaojin Guo, Zheng He, Li Lyu, Norton Tomas, Kai Liu*.<br>
		<p><em>11th European Conference on Precision Livestock Farming</em> (<i><b>ECPLF 2024</b></i>), Sep, 2024 <br>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	
    <tr>	
	    	<td width="206">
		<img src="./Figs/DeMVpp-YOLO.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>DeMVpp-YOLO: A Lightweight Pig Behavior Detection Model for Improved Pig Health Management in Farrowing Pens</b> <br>
		Zhaojin Guo, Li Lyu, Zheng He, <b>Axiu Mao</b>, Endai Huang, Kai Liu*.<br>
		<p><em>2023 International Symposium on Animal Environment and Welfare</em> (<i><b>ISAEW 2023</b></i>), Oct, 2023 <br>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	
    <tr>	
	    	<td width="206">
		<img src="./Figs/usplf2023.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Robust Animal Activity Recognition Using Wearable Sensors: A Correlation Distillation-based Information Recovery Method Toward Data Having Low Sampling Rates</b> <br>
		<b>Axiu Mao</b>, Endai Huang, Meilu Zhu, Kai Liu*.<br>
		<p><em>2nd U.S. Precision Livestock Farming Conference</em> (<i><b>USPLF 2023</b></i>), May, 2023 <br>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>

   <tr>	
	    	<td width="206">
		<img src="./Figs/Gan_usplf2023.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Occlusion-resistant Locomotion Analysis of Piglets Using Amodal Instance Segmentation</b> <br>
		Haiming Gan, <b>Axiu Mao</b>, Cheryl Natalie Sze, Endai Huang, Maria Camila Ceballos, Thomas D. Parsons, Kai Liu*.<br>
		<p><em>2nd U.S. Precision Livestock Farming Conference</em> (<i><b>USPLF 2023</b></i>), May, 2023 <br>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	
    <tr>	
	    	<td width="206">
		<img src="./Figs/ecplf2022.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Uniting Farms: Federated Learning for Sensory-based Animal Activity Recognition</b> <br>
		<b>Axiu Mao</b>, Endai Huang, Haiming Gan, Kai Liu*.<br>
		<p><em>2022 European Conference on Precision Livestock Farming</em> (<i><b>ECPLF 2022</b></i>), Aug, 2022 <br>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
		
    <tr>	
	    	<td width="206">
		<img src="./Figs/huang_ecplf2022.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Occlusion Resistant Spatiotemporal Analysis of Pig Distribution Pattern in Farrowing Pens Using Centrer Clustering Network</b> <br>
		Endai Huang, <b>Axiu Mao</b>, Haiming Gan, Kai Liu*.<br>
		<p><em>2022 European Conference on Precision Livestock Farming</em> (<i><b>ECPLF 2022</b></i>), Aug, 2022 <br>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr> 

    <tr>	
		<td width="206">
		<img src="./Figs/CMI-Net.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Cross-Modality Interaction Network for Equine Activity Recognition Using Time-Series Motion Data</b> <br>
		<b>Axiu Mao</b>, Endai Huang, Weitao Xu, Kai Liu*.<br>
		<p><em>2021 International Symposium on Animal Environment and Welfare</em> (<i><b>ISAEW 2021</b></i>), Oct, 2021 <br>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>	
     
     <tr>	
		<td width="206">
		<img src="./Figs/Key Frame Selection.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>A Key Frame Selection Method for Creating Deep Learning Training Set in Animal Research Involving Time-Series Video Data</b> <br>
		Endai Huang, <b>Axiu Mao</b>, Haiming Gan, Kai Liu*.<br>
		<p><em>2021 International Symposium on Animal Environment and Welfare</em> (<i><b>ISAEW 2021</b></i>), Oct, 2021 <br>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
	
    <tr>	
		<td width="206">
		<img src="./Figs/Capacity Limit.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Capacity Limit of Deep Learning Methods on Scenarios of Pigs in Farrowing Pen under Occlusion</b> <br>
		Endai Huang, <b>Axiu Mao</b>, Maria Camila Ceballos, Thomas D. Parsons, Kai Liu*.<br>
		<p><em>American Society of Agricultural and Biological Engineers</em> (<i><b>ASABE 2021</b></i>) , Jul, 2021 <br>
	        [<a href="https://elibrary.asabe.org/abstract.asp?JID=5&AID=52461&CID=virt2021&T=1">paper</a>]
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>	
		
    <tr>	
		<td width="206">
		<img src="./Figs/feather condition.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><b>Deep Learning-based Assessment of Laying-hen Feather Conditions Using Color and Thermal Images</b> <br>
		Endai Huang, <b>Axiu Mao</b>, Kai Liu*, Yueju Xue.<br>
		<p><em>2nd Asian Conference on Precision Livestock Farming</em> (<i><b>ACPLF 2020</b></i>), Oct, 2020 <br>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>	
		
		
    
   
   
</tbody></table>
	
<h2><font face="Arial"> Honors & Awards </font></h2>
<ul style="list-style-type:none">
	  <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
	      Outstanding Faculty Award of Annual Assessment, School of Communication Engineering, 2024<br>
	      Second Runner-Up, Huawei Developer Competition 2023 - Asia Pacific, 2023<br>
	      Bronze Award, 9th China International College Students' 'Internet +' Innovation and Entrepreneurship Competition, 2023<br>
	      Silver Award, 8th China International College Students' 'Internet +' Innovation and Entrepreneurship Competition, 2022<br>
	      Research Tuition Scholarship (RTS), City University of Hong Kong, 2022 - 2023<br>
	      Outstanding Graduate Student Paper and Presentation Award at ISAEW, 2021<br>
	      Outstanding Graduates of Zhejiang Province, 2019<br>
	      Meritorious Winner, Mathematical Contest in Modeling (MCM), 2018<br>
	      First Prize, 10th National Mathematics Competition, 2018<br>
	      First Prize, Physics Innovation Competition in Zhejiang Province, 2018<br>
	      First Prize, Higher Mathematics Competition in Zhejiang Province, 2018<br>
	      First Prize, National University Mathematical Modeling Competition in Zhejiang Competition Area, 2017<br>
	  </font> </p> 
         
</ul>
	 -->
 
<div id="footer">
	<div id="footer-text"></div>
	
        <p><center>
      	<div id="clustrmaps-widget" style="width:40%">

	<script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=wKcWVnadbANTeZkfbjX71Ux442ZlQ7yo13IpNaHQUKg&cl=ffffff&w=a"></script>
 
	
	</div>
	<p><center><font face="Arial">
        <br>
            &copy; Qian Zheng | Last updated: June. 2025
        </font></center></p>
		
</div>
</body></html>
